{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from keras.regularizers import l2\n",
    "# from keras.regularizers import l1\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout\n",
    "# from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_archivo_train = f'trainReg.txt'\n",
    "ruta_archivo_test = f'testReg.txt'\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "# Ajustar el escalador en los datos de entrenamiento y transformar los datos\n",
    "#train_tot = scaler.fit_transform(pd.read_csv(ruta_archivo_train, delimiter=','))\n",
    "#test_tot = scaler.fit_transform(pd.read_csv(ruta_archivo_test, delimiter=','))\n",
    "train_tot = pd.read_csv(ruta_archivo_train, delimiter=',')\n",
    "\n",
    "test_tot = pd.read_csv(ruta_archivo_test, delimiter=',')\n",
    "\n",
    "# print(train_tot.head())\n",
    "# print(test_tot.head())\n",
    "\n",
    "\n",
    "x_train_ori = train_tot[train_tot.columns[~train_tot.columns.isin([\"V1\", \"V4\"])]]\n",
    "y_train_ori =train_tot[\"V1\"]\n",
    "x_test_ori =test_tot[test_tot.columns[~test_tot.columns.isin([\"Id\", \"V4\"])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_train_ori, y_train_ori, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54445, 89), (23334, 89), (54445,), (23334,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 54445 entries, 11149 to 1419\n",
      "Data columns (total 89 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   V2      54445 non-null  float64\n",
      " 1   V3      54445 non-null  float64\n",
      " 2   V5      54445 non-null  float64\n",
      " 3   V6      54445 non-null  float64\n",
      " 4   V7      54445 non-null  float64\n",
      " 5   V8      54445 non-null  float64\n",
      " 6   V9      54445 non-null  float64\n",
      " 7   V10     54445 non-null  float64\n",
      " 8   V11     54445 non-null  float64\n",
      " 9   V12     54445 non-null  float64\n",
      " 10  V13     54445 non-null  float64\n",
      " 11  V14     54445 non-null  float64\n",
      " 12  V15     54445 non-null  float64\n",
      " 13  V16     54445 non-null  float64\n",
      " 14  V17     54445 non-null  float64\n",
      " 15  V18     54445 non-null  float64\n",
      " 16  V19     54445 non-null  float64\n",
      " 17  V20     54445 non-null  float64\n",
      " 18  V21     54445 non-null  float64\n",
      " 19  V22     54445 non-null  float64\n",
      " 20  V23     54445 non-null  float64\n",
      " 21  V24     54445 non-null  float64\n",
      " 22  V25     54445 non-null  float64\n",
      " 23  V26     54445 non-null  float64\n",
      " 24  V27     54445 non-null  float64\n",
      " 25  V28     54445 non-null  float64\n",
      " 26  V29     54445 non-null  float64\n",
      " 27  V30     54445 non-null  float64\n",
      " 28  V31     54445 non-null  float64\n",
      " 29  V32     54445 non-null  float64\n",
      " 30  V33     54445 non-null  float64\n",
      " 31  V34     54445 non-null  float64\n",
      " 32  V35     54445 non-null  float64\n",
      " 33  V36     54445 non-null  float64\n",
      " 34  V37     54445 non-null  float64\n",
      " 35  V38     54445 non-null  float64\n",
      " 36  V39     54445 non-null  float64\n",
      " 37  V40     54445 non-null  float64\n",
      " 38  V41     54445 non-null  float64\n",
      " 39  V42     54445 non-null  float64\n",
      " 40  V43     54445 non-null  float64\n",
      " 41  V44     54445 non-null  float64\n",
      " 42  V45     54445 non-null  float64\n",
      " 43  V46     54445 non-null  float64\n",
      " 44  V47     54445 non-null  float64\n",
      " 45  V48     54445 non-null  float64\n",
      " 46  V49     54445 non-null  float64\n",
      " 47  V50     54445 non-null  float64\n",
      " 48  V51     54445 non-null  float64\n",
      " 49  V52     54445 non-null  float64\n",
      " 50  V53     54445 non-null  float64\n",
      " 51  V54     54445 non-null  float64\n",
      " 52  V55     54445 non-null  float64\n",
      " 53  V56     54445 non-null  float64\n",
      " 54  V57     54445 non-null  float64\n",
      " 55  V58     54445 non-null  float64\n",
      " 56  V59     54445 non-null  float64\n",
      " 57  V60     54445 non-null  float64\n",
      " 58  V61     54445 non-null  float64\n",
      " 59  V62     54445 non-null  float64\n",
      " 60  V63     54445 non-null  float64\n",
      " 61  V64     54445 non-null  float64\n",
      " 62  V65     54445 non-null  float64\n",
      " 63  V66     54445 non-null  float64\n",
      " 64  V67     54445 non-null  float64\n",
      " 65  V68     54445 non-null  float64\n",
      " 66  V69     54445 non-null  float64\n",
      " 67  V70     54445 non-null  float64\n",
      " 68  V71     54445 non-null  float64\n",
      " 69  V72     54445 non-null  float64\n",
      " 70  V73     54445 non-null  float64\n",
      " 71  V74     54445 non-null  float64\n",
      " 72  V75     54445 non-null  float64\n",
      " 73  V76     54445 non-null  float64\n",
      " 74  V77     54445 non-null  float64\n",
      " 75  V78     54445 non-null  float64\n",
      " 76  V79     54445 non-null  float64\n",
      " 77  V80     54445 non-null  float64\n",
      " 78  V81     54445 non-null  float64\n",
      " 79  V82     54445 non-null  float64\n",
      " 80  V83     54445 non-null  float64\n",
      " 81  V84     54445 non-null  float64\n",
      " 82  V85     54445 non-null  float64\n",
      " 83  V86     54445 non-null  float64\n",
      " 84  V87     54445 non-null  float64\n",
      " 85  V88     54445 non-null  float64\n",
      " 86  V89     54445 non-null  float64\n",
      " 87  V90     54445 non-null  float64\n",
      " 88  V91     54445 non-null  float64\n",
      "dtypes: float64(89)\n",
      "memory usage: 37.4 MB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scale = scaler.transform(x_train)\n",
    "x_test_scale = scaler.transform(x_test)\n",
    "x_test_scale_ori = scaler.transform(x_test_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar PCA a los datos de entrenamiento y prueba con 23 componentes\n",
    "n_components = 89\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "pca.fit(x_train_scale)\n",
    "\n",
    "x_train_pca = pca.transform(x_train_scale)\n",
    "x_test_pca = pca.transform(x_test_scale)\n",
    "x_test_pca_ori = pca.transform(x_test_scale_ori)\n",
    "# Convert NumPy arrays to Pandas DataFrames\n",
    "columns = [f\"PC{i}\" for i in range(1, n_components + 1)]\n",
    "x_train_pca_df = pd.DataFrame(x_train_pca, columns=columns)\n",
    "x_test_pca_df = pd.DataFrame(x_test_pca, columns=columns)\n",
    "x_test_pca_ori_df = pd.DataFrame(x_test_pca_ori, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC80</th>\n",
       "      <th>PC81</th>\n",
       "      <th>PC82</th>\n",
       "      <th>PC83</th>\n",
       "      <th>PC84</th>\n",
       "      <th>PC85</th>\n",
       "      <th>PC86</th>\n",
       "      <th>PC87</th>\n",
       "      <th>PC88</th>\n",
       "      <th>PC89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.800417</td>\n",
       "      <td>-1.048593</td>\n",
       "      <td>-2.462892</td>\n",
       "      <td>-1.903880</td>\n",
       "      <td>-2.706123</td>\n",
       "      <td>0.126593</td>\n",
       "      <td>0.112773</td>\n",
       "      <td>-1.088876</td>\n",
       "      <td>0.519053</td>\n",
       "      <td>0.949751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046102</td>\n",
       "      <td>-0.191445</td>\n",
       "      <td>0.254158</td>\n",
       "      <td>-0.171608</td>\n",
       "      <td>-0.041422</td>\n",
       "      <td>-0.052408</td>\n",
       "      <td>0.068220</td>\n",
       "      <td>0.151329</td>\n",
       "      <td>-0.018917</td>\n",
       "      <td>0.164452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.531006</td>\n",
       "      <td>-1.571477</td>\n",
       "      <td>-4.191237</td>\n",
       "      <td>1.132363</td>\n",
       "      <td>-3.072745</td>\n",
       "      <td>-0.844856</td>\n",
       "      <td>3.226900</td>\n",
       "      <td>-0.369838</td>\n",
       "      <td>-0.544767</td>\n",
       "      <td>0.127943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569895</td>\n",
       "      <td>-0.934294</td>\n",
       "      <td>-0.097634</td>\n",
       "      <td>0.413375</td>\n",
       "      <td>0.239784</td>\n",
       "      <td>0.509209</td>\n",
       "      <td>-0.053643</td>\n",
       "      <td>0.017514</td>\n",
       "      <td>0.397854</td>\n",
       "      <td>0.353449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.635572</td>\n",
       "      <td>-2.491409</td>\n",
       "      <td>-2.623165</td>\n",
       "      <td>4.307601</td>\n",
       "      <td>1.001659</td>\n",
       "      <td>-0.501623</td>\n",
       "      <td>0.094527</td>\n",
       "      <td>0.432506</td>\n",
       "      <td>-0.199316</td>\n",
       "      <td>-1.306413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769221</td>\n",
       "      <td>0.142313</td>\n",
       "      <td>-0.612615</td>\n",
       "      <td>0.041553</td>\n",
       "      <td>0.090951</td>\n",
       "      <td>0.189377</td>\n",
       "      <td>-0.573533</td>\n",
       "      <td>0.210116</td>\n",
       "      <td>0.176411</td>\n",
       "      <td>0.005857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.244709</td>\n",
       "      <td>0.009989</td>\n",
       "      <td>1.520027</td>\n",
       "      <td>2.107475</td>\n",
       "      <td>-0.679656</td>\n",
       "      <td>-0.993198</td>\n",
       "      <td>-1.124388</td>\n",
       "      <td>1.164868</td>\n",
       "      <td>-0.760511</td>\n",
       "      <td>2.800769</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.340773</td>\n",
       "      <td>-0.034804</td>\n",
       "      <td>0.014936</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>-0.216965</td>\n",
       "      <td>0.243134</td>\n",
       "      <td>-0.081667</td>\n",
       "      <td>0.011710</td>\n",
       "      <td>-0.198955</td>\n",
       "      <td>-0.351908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.292275</td>\n",
       "      <td>0.616649</td>\n",
       "      <td>-0.609644</td>\n",
       "      <td>-2.238110</td>\n",
       "      <td>-0.776298</td>\n",
       "      <td>0.663033</td>\n",
       "      <td>-0.684003</td>\n",
       "      <td>-1.915263</td>\n",
       "      <td>0.214779</td>\n",
       "      <td>-0.211680</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.391347</td>\n",
       "      <td>-0.200085</td>\n",
       "      <td>0.256393</td>\n",
       "      <td>0.291201</td>\n",
       "      <td>-0.153328</td>\n",
       "      <td>-0.116602</td>\n",
       "      <td>0.224596</td>\n",
       "      <td>-0.063850</td>\n",
       "      <td>0.184580</td>\n",
       "      <td>-0.098347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54440</th>\n",
       "      <td>-3.731527</td>\n",
       "      <td>-1.702200</td>\n",
       "      <td>1.968426</td>\n",
       "      <td>0.728472</td>\n",
       "      <td>-0.327639</td>\n",
       "      <td>-0.158400</td>\n",
       "      <td>1.379059</td>\n",
       "      <td>-0.232182</td>\n",
       "      <td>-0.210272</td>\n",
       "      <td>0.227191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026098</td>\n",
       "      <td>0.204531</td>\n",
       "      <td>0.316552</td>\n",
       "      <td>-0.198237</td>\n",
       "      <td>-0.097420</td>\n",
       "      <td>0.132575</td>\n",
       "      <td>0.189118</td>\n",
       "      <td>-0.191142</td>\n",
       "      <td>0.125224</td>\n",
       "      <td>-0.027779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54441</th>\n",
       "      <td>-4.232238</td>\n",
       "      <td>-1.034800</td>\n",
       "      <td>1.247961</td>\n",
       "      <td>0.670156</td>\n",
       "      <td>0.064895</td>\n",
       "      <td>0.137860</td>\n",
       "      <td>-0.387643</td>\n",
       "      <td>0.028448</td>\n",
       "      <td>-0.216407</td>\n",
       "      <td>-1.261008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248311</td>\n",
       "      <td>-0.031598</td>\n",
       "      <td>0.272810</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>-0.057352</td>\n",
       "      <td>0.098590</td>\n",
       "      <td>-0.066298</td>\n",
       "      <td>-0.053715</td>\n",
       "      <td>-0.125487</td>\n",
       "      <td>0.114177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54442</th>\n",
       "      <td>2.718412</td>\n",
       "      <td>6.907340</td>\n",
       "      <td>-3.213658</td>\n",
       "      <td>-1.794978</td>\n",
       "      <td>-0.014764</td>\n",
       "      <td>-1.699097</td>\n",
       "      <td>-0.993768</td>\n",
       "      <td>-1.926511</td>\n",
       "      <td>0.008270</td>\n",
       "      <td>-1.773467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083142</td>\n",
       "      <td>0.217633</td>\n",
       "      <td>-0.444122</td>\n",
       "      <td>0.401213</td>\n",
       "      <td>0.391834</td>\n",
       "      <td>0.323249</td>\n",
       "      <td>0.301229</td>\n",
       "      <td>-0.293882</td>\n",
       "      <td>-0.062669</td>\n",
       "      <td>-0.139916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54443</th>\n",
       "      <td>-0.849227</td>\n",
       "      <td>-3.362063</td>\n",
       "      <td>-4.446842</td>\n",
       "      <td>0.903412</td>\n",
       "      <td>-1.740605</td>\n",
       "      <td>-1.255641</td>\n",
       "      <td>1.484005</td>\n",
       "      <td>1.689847</td>\n",
       "      <td>1.033102</td>\n",
       "      <td>-0.185772</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248262</td>\n",
       "      <td>-0.487867</td>\n",
       "      <td>0.444995</td>\n",
       "      <td>0.016783</td>\n",
       "      <td>0.013068</td>\n",
       "      <td>0.732499</td>\n",
       "      <td>-0.425857</td>\n",
       "      <td>0.163947</td>\n",
       "      <td>0.120960</td>\n",
       "      <td>0.404139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54444</th>\n",
       "      <td>2.886152</td>\n",
       "      <td>-1.364056</td>\n",
       "      <td>0.589193</td>\n",
       "      <td>0.389005</td>\n",
       "      <td>1.474364</td>\n",
       "      <td>-0.119456</td>\n",
       "      <td>-0.985556</td>\n",
       "      <td>-0.499846</td>\n",
       "      <td>0.799115</td>\n",
       "      <td>-0.638874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296747</td>\n",
       "      <td>-0.548568</td>\n",
       "      <td>-0.216105</td>\n",
       "      <td>-0.179407</td>\n",
       "      <td>0.140208</td>\n",
       "      <td>-0.346171</td>\n",
       "      <td>0.340721</td>\n",
       "      <td>0.651366</td>\n",
       "      <td>0.096935</td>\n",
       "      <td>0.319801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54445 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0     -1.800417 -1.048593 -2.462892 -1.903880 -2.706123  0.126593  0.112773   \n",
       "1      0.531006 -1.571477 -4.191237  1.132363 -3.072745 -0.844856  3.226900   \n",
       "2     -2.635572 -2.491409 -2.623165  4.307601  1.001659 -0.501623  0.094527   \n",
       "3     -2.244709  0.009989  1.520027  2.107475 -0.679656 -0.993198 -1.124388   \n",
       "4      2.292275  0.616649 -0.609644 -2.238110 -0.776298  0.663033 -0.684003   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "54440 -3.731527 -1.702200  1.968426  0.728472 -0.327639 -0.158400  1.379059   \n",
       "54441 -4.232238 -1.034800  1.247961  0.670156  0.064895  0.137860 -0.387643   \n",
       "54442  2.718412  6.907340 -3.213658 -1.794978 -0.014764 -1.699097 -0.993768   \n",
       "54443 -0.849227 -3.362063 -4.446842  0.903412 -1.740605 -1.255641  1.484005   \n",
       "54444  2.886152 -1.364056  0.589193  0.389005  1.474364 -0.119456 -0.985556   \n",
       "\n",
       "            PC8       PC9      PC10  ...      PC80      PC81      PC82  \\\n",
       "0     -1.088876  0.519053  0.949751  ...  0.046102 -0.191445  0.254158   \n",
       "1     -0.369838 -0.544767  0.127943  ...  0.569895 -0.934294 -0.097634   \n",
       "2      0.432506 -0.199316 -1.306413  ... -0.769221  0.142313 -0.612615   \n",
       "3      1.164868 -0.760511  2.800769  ... -0.340773 -0.034804  0.014936   \n",
       "4     -1.915263  0.214779 -0.211680  ... -0.391347 -0.200085  0.256393   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "54440 -0.232182 -0.210272  0.227191  ...  0.026098  0.204531  0.316552   \n",
       "54441  0.028448 -0.216407 -1.261008  ... -0.248311 -0.031598  0.272810   \n",
       "54442 -1.926511  0.008270 -1.773467  ...  0.083142  0.217633 -0.444122   \n",
       "54443  1.689847  1.033102 -0.185772  ... -0.248262 -0.487867  0.444995   \n",
       "54444 -0.499846  0.799115 -0.638874  ... -0.296747 -0.548568 -0.216105   \n",
       "\n",
       "           PC83      PC84      PC85      PC86      PC87      PC88      PC89  \n",
       "0     -0.171608 -0.041422 -0.052408  0.068220  0.151329 -0.018917  0.164452  \n",
       "1      0.413375  0.239784  0.509209 -0.053643  0.017514  0.397854  0.353449  \n",
       "2      0.041553  0.090951  0.189377 -0.573533  0.210116  0.176411  0.005857  \n",
       "3      0.026822 -0.216965  0.243134 -0.081667  0.011710 -0.198955 -0.351908  \n",
       "4      0.291201 -0.153328 -0.116602  0.224596 -0.063850  0.184580 -0.098347  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "54440 -0.198237 -0.097420  0.132575  0.189118 -0.191142  0.125224 -0.027779  \n",
       "54441  0.003516 -0.057352  0.098590 -0.066298 -0.053715 -0.125487  0.114177  \n",
       "54442  0.401213  0.391834  0.323249  0.301229 -0.293882 -0.062669 -0.139916  \n",
       "54443  0.016783  0.013068  0.732499 -0.425857  0.163947  0.120960  0.404139  \n",
       "54444 -0.179407  0.140208 -0.346171  0.340721  0.651366  0.096935  0.319801  \n",
       "\n",
       "[54445 rows x 89 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=30, max_features=&#x27;sqrt&#x27;, min_samples_leaf=3,\n",
       "                      random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=30, max_features=&#x27;sqrt&#x27;, min_samples_leaf=3,\n",
       "                      random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=30, max_features='sqrt', min_samples_leaf=3,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Gradient Boosting Regressor model\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    max_features='sqrt',\n",
    "    max_depth=30,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=3,\n",
    ")\n",
    "# Train the model\n",
    "model.fit(x_train_pca_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse\n",
      "24.678082693277272\n",
      "mse\n",
      "90.11659941269727\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_train = model.predict(x_train_pca_df)\n",
    "y_pred_test = model.predict(x_test_pca_df)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"mse\")\n",
    "print(mse_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "print(\"mse\")\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "y_pred_test_ori = model.predict(x_test_pca_ori_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id            y\n",
      "0   1  2003.900833\n",
      "1   2  1997.359920\n",
      "2   3  2000.168710\n",
      "3   4  2002.754024\n",
      "4   5  2004.414182\n"
     ]
    }
   ],
   "source": [
    "# Create the results DataFrame\n",
    "results = pd.DataFrame({\"Id\": test_tot[\"Id\"], \"y\": y_pred_test_ori.flatten()})\n",
    "\n",
    "# Print the first few rows of the results DataFrame\n",
    "print(results.head())\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "# ruta_resultados = r'C:\\Users\\Usuario\\Downloads\\Statistical\\Statistical\\proy\\Regre\\boost11100.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_resultados = f'resultados_rf_100.csv'\n",
    "\n",
    "results.to_csv(ruta_resultados, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_new'] = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_1'] = df['y_new'].round()\n",
    "df['y'] = df['y_new_new'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>y</th>\n",
       "      <th>y_new</th>\n",
       "      <th>y_new_new</th>\n",
       "      <th>y_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>2006.405057</td>\n",
       "      <td>2006.005057</td>\n",
       "      <td>2006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>1998.716301</td>\n",
       "      <td>1998.316301</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>2005.587338</td>\n",
       "      <td>2005.987338</td>\n",
       "      <td>2006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>2002.052711</td>\n",
       "      <td>2001.652711</td>\n",
       "      <td>2002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>2004.248900</td>\n",
       "      <td>2004.648900</td>\n",
       "      <td>2004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18652</th>\n",
       "      <td>18653</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1997.836605</td>\n",
       "      <td>1997.436605</td>\n",
       "      <td>1998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18653</th>\n",
       "      <td>18654</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>2002.856300</td>\n",
       "      <td>2002.456300</td>\n",
       "      <td>2003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18654</th>\n",
       "      <td>18655</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1999.269548</td>\n",
       "      <td>1999.669548</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18655</th>\n",
       "      <td>18656</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2000.907672</td>\n",
       "      <td>2000.507672</td>\n",
       "      <td>2001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18656</th>\n",
       "      <td>18657</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>1998.117202</td>\n",
       "      <td>1997.717202</td>\n",
       "      <td>1998.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18657 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id       y        y_new    y_new_new     y_1\n",
       "0          1  2006.0  2006.405057  2006.005057  2006.0\n",
       "1          2  1998.0  1998.716301  1998.316301  1999.0\n",
       "2          3  2006.0  2005.587338  2005.987338  2006.0\n",
       "3          4  2002.0  2002.052711  2001.652711  2002.0\n",
       "4          5  2005.0  2004.248900  2004.648900  2004.0\n",
       "...      ...     ...          ...          ...     ...\n",
       "18652  18653  1997.0  1997.836605  1997.436605  1998.0\n",
       "18653  18654  2002.0  2002.856300  2002.456300  2003.0\n",
       "18654  18655  2000.0  1999.269548  1999.669548  1999.0\n",
       "18655  18656  2001.0  2000.907672  2000.507672  2001.0\n",
       "18656  18657  1998.0  1998.117202  1997.717202  1998.0\n",
       "\n",
       "[18657 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_resultados = f'y_test.csv'\n",
    "\n",
    "df[['Id', 'y']].to_csv(ruta_resultados, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_changes = np.random.choice([-0.4, 0.4], size=len(df['y_new']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_new_new'] = df['y_new'] + random_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[1;32mc:\\Users\\SGM\\OneDrive\\Documentos\\Santiago González Montealegre\\Materias Uniandes\\2023-20\\Statistical Learning\\Proyecto\\Regresion\\b.ipynb Cell 10\u001b[0m line \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SGM/OneDrive/Documentos/Santiago%20Gonz%C3%A1lez%20Montealegre/Materias%20Uniandes/2023-20/Statistical%20Learning/Proyecto/Regresion/b.ipynb#X31sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SGM/OneDrive/Documentos/Santiago%20Gonz%C3%A1lez%20Montealegre/Materias%20Uniandes/2023-20/Statistical%20Learning/Proyecto/Regresion/b.ipynb#X31sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     estimator\u001b[39m=\u001b[39mrf_model,\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SGM/OneDrive/Documentos/Santiago%20Gonz%C3%A1lez%20Montealegre/Materias%20Uniandes/2023-20/Statistical%20Learning/Proyecto/Regresion/b.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     param_grid\u001b[39m=\u001b[39mparam_grid, \n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SGM/OneDrive/Documentos/Santiago%20Gonz%C3%A1lez%20Montealegre/Materias%20Uniandes/2023-20/Statistical%20Learning/Proyecto/Regresion/b.ipynb#X31sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SGM/OneDrive/Documentos/Santiago%20Gonz%C3%A1lez%20Montealegre/Materias%20Uniandes/2023-20/Statistical%20Learning/Proyecto/Regresion/b.ipynb#X31sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m )\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SGM/OneDrive/Documentos/Santiago%20Gonz%C3%A1lez%20Montealegre/Materias%20Uniandes/2023-20/Statistical%20Learning/Proyecto/Regresion/b.ipynb#X31sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Paso 6: Ajustar el modelo utilizando GridSearchCV\u001b[39;00m\n",
      "\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/SGM/OneDrive/Documentos/Santiago%20Gonz%C3%A1lez%20Montealegre/Materias%20Uniandes/2023-20/Statistical%20Learning/Proyecto/Regresion/b.ipynb#X31sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(x_train_pca_df, y_train)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n",
      "\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n",
      "\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n",
      "\u001b[0;32m    871\u001b[0m     )\n",
      "\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n",
      "\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n",
      "\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n",
      "\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n",
      "\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n",
      "\u001b[0;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n",
      "\u001b[0;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n",
      "\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n",
      "\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n",
      "\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n",
      "\u001b[0;32m    819\u001b[0m         )\n",
      "\u001b[0;32m    820\u001b[0m     )\n",
      "\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n",
      "\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n",
      "\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n",
      "\u001b[0;32m    825\u001b[0m         X,\n",
      "\u001b[0;32m    826\u001b[0m         y,\n",
      "\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n",
      "\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n",
      "\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n",
      "\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n",
      "\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n",
      "\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n",
      "\u001b[0;32m    833\u001b[0m     )\n",
      "\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n",
      "\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n",
      "\u001b[0;32m    836\u001b[0m     )\n",
      "\u001b[0;32m    837\u001b[0m )\n",
      "\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n",
      "\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m    844\u001b[0m     )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n",
      "\u001b[0;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n",
      "\u001b[0;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n",
      "\u001b[0;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n",
      "\u001b[0;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n",
      "\u001b[1;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n",
      "\u001b[0;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n",
      "\u001b[0;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n",
      "\u001b[1;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n",
      "\u001b[0;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n",
      "\u001b[0;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n",
      "\u001b[0;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n",
      "\u001b[0;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n",
      "\u001b[0;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n",
      "\u001b[0;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n",
      "\u001b[0;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n",
      "\u001b[0;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n",
      "\u001b[0;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n",
      "\u001b[1;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n",
      "\u001b[0;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[0;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n",
      "\u001b[0;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n",
      "\u001b[0;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "# Paso 4: Crear el modelo de RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Paso 5: Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid, \n",
    "    scoring='neg_mean_squared_error', \n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "# Paso 6: Ajustar el modelo utilizando GridSearchCV\n",
    "grid_search.fit(x_train_pca_df, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
